{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image 1/37: raw_images\\photo_2024-12-16_19-09-49 (2).jpg\n",
      "Processing image 2/37: raw_images\\photo_2024-12-16_19-09-49 (3).jpg\n",
      "Processing image 3/37: raw_images\\photo_2024-12-16_19-09-49 (4).jpg\n",
      "Processing image 4/37: raw_images\\photo_2024-12-16_19-09-49 (5).jpg\n",
      "Processing image 5/37: raw_images\\photo_2024-12-16_19-09-49.jpg\n",
      "Processing image 6/37: raw_images\\photo_2024-12-16_19-09-50 (2).jpg\n",
      "Processing image 7/37: raw_images\\photo_2024-12-16_19-09-50 (3).jpg\n",
      "Processing image 8/37: raw_images\\photo_2024-12-16_19-09-50 (4).jpg\n",
      "Processing image 9/37: raw_images\\photo_2024-12-16_19-09-50 (5).jpg\n",
      "Processing image 10/37: raw_images\\photo_2024-12-16_19-09-50 (6).jpg\n",
      "Processing image 11/37: raw_images\\photo_2024-12-16_19-09-50 (7).jpg\n",
      "Processing image 12/37: raw_images\\photo_2024-12-16_19-09-50 (8).jpg\n",
      "Processing image 13/37: raw_images\\photo_2024-12-16_19-09-50.jpg\n",
      "Processing image 14/37: raw_images\\photo_2024-12-16_19-09-51 (2).jpg\n",
      "Processing image 15/37: raw_images\\photo_2024-12-16_19-09-51 (3).jpg\n",
      "Processing image 16/37: raw_images\\photo_2024-12-16_19-09-51 (4).jpg\n",
      "Processing image 17/37: raw_images\\photo_2024-12-16_19-09-51 (5).jpg\n",
      "Processing image 18/37: raw_images\\photo_2024-12-16_19-09-51.jpg\n",
      "Processing image 19/37: raw_images\\photo_2024-12-16_19-09-52 (2).jpg\n",
      "Processing image 20/37: raw_images\\photo_2024-12-16_19-09-52.jpg\n",
      "Processing image 21/37: raw_images\\photo_2024-12-16_19-10-09 (2).jpg\n",
      "Processing image 22/37: raw_images\\photo_2024-12-16_19-10-09 (3).jpg\n",
      "Processing image 23/37: raw_images\\photo_2024-12-16_19-10-09.jpg\n",
      "Processing image 24/37: raw_images\\photo_2024-12-16_19-19-51.jpg\n",
      "Processing image 25/37: raw_images\\photo_2024-12-16_19-20-04.jpg\n",
      "Processing image 26/37: raw_images\\photo_2024-12-16_19-20-40 (2).jpg\n",
      "Processing image 27/37: raw_images\\photo_2024-12-16_19-20-40 (3).jpg\n",
      "Processing image 28/37: raw_images\\photo_2024-12-16_19-20-40.jpg\n",
      "Processing image 29/37: raw_images\\photo_2024-12-16_19-20-41 (2).jpg\n",
      "Processing image 30/37: raw_images\\photo_2024-12-16_19-20-41 (3).jpg\n",
      "No face detected in: raw_images\\photo_2024-12-16_19-20-41 (3).jpg\n",
      "Processing image 31/37: raw_images\\photo_2024-12-16_19-20-41 (4).jpg\n",
      "Processing image 32/37: raw_images\\photo_2024-12-16_19-20-41 (5).jpg\n",
      "No face detected in: raw_images\\photo_2024-12-16_19-20-41 (5).jpg\n",
      "Processing image 33/37: raw_images\\photo_2024-12-16_19-20-41.jpg\n",
      "Processing image 34/37: raw_images\\photo_2024-12-16_19-21-52 (2).jpg\n",
      "Processing image 35/37: raw_images\\photo_2024-12-16_19-21-52 (3).jpg\n",
      "Processing image 36/37: raw_images\\photo_2024-12-16_19-21-52.jpg\n",
      "Processing image 37/37: raw_images\\photo_2024-12-16_19-24-12.jpg\n",
      "\n",
      "Dataset preparation completed. Processed images saved to: processed_dataset\n",
      "Total original images: 37\n",
      "Total dataset size (including augmentations): 148\n",
      "Metadata file created: processed_dataset\\metadata.jsonl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import mediapipe as mp\n",
    "import albumentations as A\n",
    "from pathlib import Path\n",
    "\n",
    "class FaceDatasetPreparator:\n",
    "    def __init__(self, input_dir, output_dir):\n",
    "        self.input_dir = Path(input_dir)\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Initialize face detection\n",
    "        self.mp_face_detection = mp.solutions.face_detection\n",
    "        self.face_detection = self.mp_face_detection.FaceDetection(\n",
    "            model_selection=1, min_detection_confidence=0.5\n",
    "        )\n",
    "        \n",
    "        # Define augmentation pipeline\n",
    "        self.transform = A.Compose([\n",
    "            A.RandomBrightnessContrast(p=0.5),\n",
    "            A.HueSaturationValue(p=0.3),\n",
    "            A.GaussNoise(p=0.2),\n",
    "            A.RandomRotate90(p=0.2),\n",
    "            A.Flip(p=0.2),\n",
    "            A.OneOf([\n",
    "                A.MotionBlur(p=0.2),\n",
    "                A.MedianBlur(blur_limit=3, p=0.1),\n",
    "                A.GaussianBlur(blur_limit=3, p=0.1),\n",
    "            ], p=0.2),\n",
    "        ])\n",
    "\n",
    "    def detect_and_crop_face(self, image):\n",
    "        \"\"\"Detect face in image and return cropped region with padding\"\"\"\n",
    "        results = self.face_detection.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        if not results.detections:\n",
    "            return None\n",
    "            \n",
    "        detection = results.detections[0]  # Use the first detected face\n",
    "        bbox = detection.location_data.relative_bounding_box\n",
    "        \n",
    "        h, w = image.shape[:2]\n",
    "        x, y = int(bbox.xmin * w), int(bbox.ymin * h)\n",
    "        width, height = int(bbox.width * w), int(bbox.height * h)\n",
    "        \n",
    "        # Add padding around face\n",
    "        padding = 0.2\n",
    "        x = max(0, int(x - width * padding))\n",
    "        y = max(0, int(y - height * padding))\n",
    "        width = min(w - x, int(width * (1 + 2 * padding)))\n",
    "        height = min(h - y, int(height * (1 + 2 * padding)))\n",
    "        \n",
    "        return image[y:y+height, x:x+width]\n",
    "\n",
    "    def process_image(self, image_path, idx):\n",
    "        \"\"\"Process single image and save original and augmented versions\"\"\"\n",
    "        image = cv2.imread(str(image_path))\n",
    "        if image is None:\n",
    "            print(f\"Failed to load image: {image_path}\")\n",
    "            return\n",
    "            \n",
    "        # Detect and crop face\n",
    "        face = self.detect_and_crop_face(image)\n",
    "        if face is None:\n",
    "            print(f\"No face detected in: {image_path}\")\n",
    "            return\n",
    "            \n",
    "        # Resize to standard size\n",
    "        face = cv2.resize(face, (512, 512))\n",
    "        \n",
    "        # Save original processed face\n",
    "        original_path = self.output_dir / f\"face_{idx:03d}.png\"\n",
    "        cv2.imwrite(str(original_path), face)\n",
    "        \n",
    "        # Generate augmented versions\n",
    "        for aug_idx in range(3):  # Create 3 augmented versions of each image\n",
    "            augmented = self.transform(image=face)['image']\n",
    "            aug_path = self.output_dir / f\"face_{idx:03d}_aug_{aug_idx}.png\"\n",
    "            cv2.imwrite(str(aug_path), augmented)\n",
    "\n",
    "    def prepare_dataset(self):\n",
    "        \"\"\"Process all images in the input directory\"\"\"\n",
    "        image_files = list(self.input_dir.glob(\"*.jpg\")) + list(self.input_dir.glob(\"*.png\"))\n",
    "        \n",
    "        for idx, image_path in enumerate(image_files):\n",
    "            print(f\"Processing image {idx+1}/{len(image_files)}: {image_path}\")\n",
    "            self.process_image(image_path, idx)\n",
    "            \n",
    "        print(f\"\\nDataset preparation completed. Processed images saved to: {self.output_dir}\")\n",
    "        print(f\"Total original images: {len(image_files)}\")\n",
    "        print(f\"Total dataset size (including augmentations): {len(image_files) * 4}\")\n",
    "\n",
    "def prepare_metadata(output_dir, prompt_prefix=\"a photo of a person\"):\n",
    "    \"\"\"Create metadata file for fine-tuning\"\"\"\n",
    "    metadata_file = Path(output_dir) / \"metadata.jsonl\"\n",
    "    image_files = list(Path(output_dir).glob(\"*.png\"))\n",
    "    \n",
    "    with open(metadata_file, \"w\") as f:\n",
    "        for image_file in image_files:\n",
    "            f.write(f'{{\"file_name\": \"{image_file.name}\", \"text\": \"{prompt_prefix}\"}}\\n')\n",
    "            \n",
    "    print(f\"Metadata file created: {metadata_file}\")\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    INPUT_DIR = \"raw_images\"    # Directory containing your original face photos\n",
    "    OUTPUT_DIR = \"processed_dataset\"  # Directory where processed images will be saved\n",
    "    \n",
    "    preparator = FaceDatasetPreparator(INPUT_DIR, OUTPUT_DIR)\n",
    "    preparator.prepare_dataset()\n",
    "    prepare_metadata(OUTPUT_DIR, prompt_prefix=\"thenmozhi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
